<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.81.0" />


<title>Ides of Machine Learning - Jack Livers&#39; Github Site</title>
<meta property="og:title" content="Ides of Machine Learning - Jack Livers&#39; Github Site">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/jacklivers/jacklivers.github.io">GitHub</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">11 min read</span>
    

    <h1 class="article-title">Ides of Machine Learning</h1>

    
    <span class="article-date">2021-03-22</span>
    

    <div class="article-content">
      
<script src="/2021/03/22/ides-of-machine-learning/index_files/header-attrs/header-attrs.js"></script>


<p>Every year come March the nation comes together for one reason, basketball. Since last year’s Madness was canceled it made the anticipation for this year that much greater. Many people fill out brackets, from sports nuts to Karen in the office who makes picks based on uniform color, mascots, anything not basketball related.</p>
<p>I haven’t filled out a bracket in many years because I haven’t seen the point, but this year I used machine learning to make my March Madness picks. Using a random forest making predictions based mainly on Possessions, Points-Per-Possession, and Efficient Field Goal Percentage, I was able to make picks with some statistical backing.</p>
<p>To do this I used game data updated through conference tournament games [Note, you’ll need to install tidyverse and zoo packages and run those libraries along with tidy models].</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.3     ✓ purrr   0.3.4
## ✓ tibble  3.0.5     ✓ dplyr   1.0.3
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(tidymodels)</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.2 ──</code></pre>
<pre><code>## ✓ broom     0.7.3      ✓ recipes   0.1.15
## ✓ dials     0.0.9      ✓ rsample   0.0.8 
## ✓ infer     0.5.4      ✓ tune      0.1.2 
## ✓ modeldata 0.1.0      ✓ workflows 0.2.1 
## ✓ parsnip   0.1.5      ✓ yardstick 0.0.7</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()</code></pre>
<pre class="r"><code>library(zoo)</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>set.seed(3673)</code></pre>
<p>I have my data and stat calculations all in on code block, along with the random forest will be the use of rolling means to predict inputs.</p>
<p>In my model, the sample size is 10, so what a rolling mean does is when we move along, we lose the first sample and add the most recent.</p>
<pre class="r"><code>rollinggames &lt;- read_csv(&quot;~/Documents/JOMC-491/Data/cbblogs1521.csv&quot;) %&gt;% mutate(
  Possessions = .5*(TeamFGA - TeamOffRebounds + TeamTurnovers + (.475 * TeamFTA)) + .5*(OpponentFGA - OpponentOffRebounds + OpponentTurnovers + (.475 * OpponentFTA)),
  PPP = TeamScore/Possessions) %&gt;%
  mutate(
    EffFGPCT = (TeamFG + (0.5*Team3P)/TeamFGA)) %&gt;%
  group_by(Team, Season) %&gt;%
  mutate(
  Rolling_Mean_Possessions = rollmean(Possessions, k=10, fill = Possessions), 
  Rolling_Mean_PPP = rollmean(PPP, k=10, fill = PPP),
  Rolling_Mean_EFG = rollmean(EffFGPCT, k=10, fill=EffFGPCT)
  ) %&gt;% ungroup() %&gt;% 
  mutate(
    Location = case_when(
    str_trim(HomeAway) == &quot;@&quot; ~ &quot;A&quot;,
    str_trim(HomeAway) == &quot;N&quot; ~ &quot;N&quot;,
    TRUE ~ &quot;H&quot;
  ),
 Outcome = case_when(
  grepl(&quot;W&quot;, W_L) ~ &quot;W&quot;, 
  grepl(&quot;L&quot;, W_L) ~ &quot;L&quot;
 )
) %&gt;%
  mutate(Outcome = as.factor(Outcome))</code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   Season = col_character(),
##   Date = col_date(format = &quot;&quot;),
##   TeamFull = col_character(),
##   Opponent = col_character(),
##   HomeAway = col_character(),
##   W_L = col_character(),
##   URL = col_character(),
##   Conference = col_character(),
##   Team = col_character()
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<p>The machine learning algorithm I decided to use to predict the bracket this year is called random forest; while I know “random forest” sounds like the subject of a psychedelic rock song, it isn’t in this case.</p>
<p>A random forest is a collection of decision trees, each decision tree has its output; the random forest averages all of those outputs and spits out the prediction.</p>
<p>The reason I chose a random forest was that it doesn’t take a long time to run and I felt it most the most effective option that would work on my computer.</p>
<div id="how-i-did-it" class="section level3">
<h3>How I Did It</h3>
<p>One of the first things I need to do is split my data into testing and training sets.</p>
<pre class="r"><code>superdata_split &lt;- initial_split(superdata, prop = .8)
superdata_train &lt;- training(superdata_split)
superdata_test &lt;- testing(superdata_split)</code></pre>
<p>Then I need a model with a definition to match.</p>
<pre class="r"><code>superdata_mod &lt;- 
  rand_forest() %&gt;% 
  set_engine(&quot;ranger&quot;) %&gt;%
  set_mode(&quot;classification&quot;)</code></pre>
<p>Now I need a recipe that will highlight which variable[s] are ID, predictors, and the outcome.</p>
<pre class="r"><code>superdata_recipe &lt;- 
  recipe(Outcome ~ ., data = superdata_train) %&gt;% 
  update_role(Team, Opponent, Date, Season, new_role = &quot;ID&quot;) %&gt;%
  step_normalize(all_predictors())

summary(superdata_recipe)</code></pre>
<pre><code>## # A tibble: 13 x 4
##    variable                          type    role      source  
##    &lt;chr&gt;                             &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;   
##  1 Season                            nominal ID        original
##  2 Team                              nominal ID        original
##  3 Date                              date    ID        original
##  4 Opponent                          nominal ID        original
##  5 Rolling_Mean_Possessions          numeric predictor original
##  6 Rolling_Mean_PPP                  numeric predictor original
##  7 Rolling_Mean_EFG                  numeric predictor original
##  8 TeamSRS                           numeric predictor original
##  9 Opponent_Rolling_Mean_Possessions numeric predictor original
## 10 Opponent_Rolling_Mean_PPP         numeric predictor original
## 11 Opponent_Rolling_Mean_EFG         numeric predictor original
## 12 OpponentSRS                       numeric predictor original
## 13 Outcome                           nominal outcome   original</code></pre>
<p>One thing I can do to make things simpler is to make a workflow.</p>
<pre class="r"><code>superdata_workflow &lt;- 
  workflow() %&gt;% 
  add_model(superdata_mod) %&gt;% 
  add_recipe(superdata_recipe)</code></pre>
<p>I can add my model and recipe to the workflow.</p>
<p>Then all I have to do when making my fit is apply the workflow since it applies the model and recipe for me. Like so:</p>
<pre class="r"><code>superdata_fit &lt;- 
  superdata_workflow %&gt;% 
  fit(data = superdata_train)</code></pre>
<pre><code>## # A tibble: 36,645 x 14
##    .pred_class Season Team  Date       Opponent Outcome Rolling_Mean_Po…
##    &lt;fct&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;fct&gt;              &lt;dbl&gt;
##  1 L           2014-… Abil… 2014-11-19 Tulsa    L                   79.6
##  2 L           2014-… Abil… 2014-11-22 Duquesne L                   79.6
##  3 L           2014-… Abil… 2014-12-06 Houston  L                   68.9
##  4 L           2014-… Abil… 2014-12-17 Loyola … L                   67.8
##  5 W           2014-… Abil… 2014-12-23 Arkansa… W                   68.7
##  6 L           2014-… Abil… 2014-12-28 Grand C… L                   68.3
##  7 W           2014-… Abil… 2015-01-04 Central… W                   68.4
##  8 W           2014-… Abil… 2015-01-10 Nicholl… W                   68.8
##  9 L           2014-… Abil… 2015-01-13 Northwe… W                   69.0
## 10 L           2014-… Abil… 2015-01-20 McNeese… L                   67.9
## # … with 36,635 more rows, and 7 more variables: Rolling_Mean_PPP &lt;dbl&gt;,
## #   Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_Possessions &lt;dbl&gt;, Opponent_Rolling_Mean_PPP &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;</code></pre>
<pre><code>## # A tibble: 36,645 x 16
##    .pred_L .pred_W .pred_class Season Team  Date       Opponent Outcome
##      &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;fct&gt;  
##  1  0.933   0.0666 L           2014-… Abil… 2014-11-19 Tulsa    L      
##  2  0.880   0.120  L           2014-… Abil… 2014-11-22 Duquesne L      
##  3  0.906   0.0940 L           2014-… Abil… 2014-12-06 Houston  L      
##  4  0.962   0.0376 L           2014-… Abil… 2014-12-17 Loyola … L      
##  5  0.256   0.744  W           2014-… Abil… 2014-12-23 Arkansa… W      
##  6  0.853   0.147  L           2014-… Abil… 2014-12-28 Grand C… L      
##  7  0.0977  0.902  W           2014-… Abil… 2015-01-04 Central… W      
##  8  0.203   0.797  W           2014-… Abil… 2015-01-10 Nicholl… W      
##  9  0.513   0.487  L           2014-… Abil… 2015-01-13 Northwe… W      
## 10  0.799   0.201  L           2014-… Abil… 2015-01-20 McNeese… L      
## # … with 36,635 more rows, and 8 more variables:
## #   Rolling_Mean_Possessions &lt;dbl&gt;, Rolling_Mean_PPP &lt;dbl&gt;,
## #   Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_Possessions &lt;dbl&gt;, Opponent_Rolling_Mean_PPP &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;</code></pre>
</div>
<div id="metrics" class="section level3">
<h3>Metrics</h3>
<p>I’m going to skip ahead a tad to look at the metrics, basically how accurate is my model. The accuracy metric takes several predictions that are correct when compared to known results. Kap is a representation of accuracy based solely on chance.</p>
<p>We’ll first look at training data, which is how good the model does with the data it already has.</p>
<pre class="r"><code>metrics(sdtrainpredict, Outcome, .pred_class)</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.981
## 2 kap      binary         0.961</code></pre>
<p>So it looks like my model has an accuracy of 98% and a kap of 96%.</p>
<pre><code>## # A tibble: 9,160 x 14
##    .pred_class Season Team  Date       Opponent Outcome Rolling_Mean_Po…
##    &lt;fct&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;fct&gt;              &lt;dbl&gt;
##  1 L           2014-… Abil… 2014-11-29 UC-Rive… L                   69.4
##  2 L           2014-… Abil… 2014-12-04 Sacrame… W                   68.5
##  3 W           2014-… Abil… 2014-12-22 South C… W                   68.6
##  4 L           2014-… Abil… 2015-01-26 Sam Hou… L                   66.4
##  5 L           2014-… Abil… 2015-02-21 Southea… L                   63.0
##  6 W           2014-… Abil… 2015-03-03 Houston… W                   79.2
##  7 L           2014-… Air … 2014-11-30 Texas T… L                   61.9
##  8 L           2014-… Air … 2014-12-20 UC-Davis L                   62.8
##  9 W           2014-… Air … 2014-12-22 Jackson… W                   62.3
## 10 L           2014-… Air … 2015-02-04 New Mex… W                   60.3
## # … with 9,150 more rows, and 7 more variables: Rolling_Mean_PPP &lt;dbl&gt;,
## #   Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_Possessions &lt;dbl&gt;, Opponent_Rolling_Mean_PPP &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;</code></pre>
<pre><code>## # A tibble: 9,160 x 16
##    .pred_L .pred_W .pred_class Season Team  Date       Opponent Outcome
##      &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;    &lt;fct&gt;  
##  1  0.834   0.166  L           2014-… Abil… 2014-11-29 UC-Rive… L      
##  2  0.939   0.0609 L           2014-… Abil… 2014-12-04 Sacrame… W      
##  3  0.230   0.770  W           2014-… Abil… 2014-12-22 South C… W      
##  4  0.950   0.0501 L           2014-… Abil… 2015-01-26 Sam Hou… L      
##  5  0.680   0.320  L           2014-… Abil… 2015-02-21 Southea… L      
##  6  0.401   0.599  W           2014-… Abil… 2015-03-03 Houston… W      
##  7  0.537   0.463  L           2014-… Air … 2014-11-30 Texas T… L      
##  8  0.610   0.390  L           2014-… Air … 2014-12-20 UC-Davis L      
##  9  0.0925  0.908  W           2014-… Air … 2014-12-22 Jackson… W      
## 10  0.676   0.324  L           2014-… Air … 2015-02-04 New Mex… W      
## # … with 9,150 more rows, and 8 more variables: Rolling_Mean_Possessions &lt;dbl&gt;,
## #   Rolling_Mean_PPP &lt;dbl&gt;, Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_Possessions &lt;dbl&gt;, Opponent_Rolling_Mean_PPP &lt;dbl&gt;,
## #   Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;</code></pre>
<p>Let’s see how the accuracy and kap differ with the testing data.</p>
<pre class="r"><code>metrics(sdtestpredict, Outcome, .pred_class)</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.718
## 2 kap      binary         0.436</code></pre>
<p>Wow, so there’s quite the difference in accuracy between known data and unknown data. Though this does make sense you’d like to see better than that around 72% accuracy and a 43% kap (remember kap is based solely on chance) when we’re trying to predict the future.</p>
<p>Maybe I can refer back to these numbers when evaluating how the model did.</p>
<p>This is where the fun begins. You’ll get to see some, but not all of my predictions. Why not all? Because that’s many lines of code and the equivalent of reading a blog about someone else’s fantasy team.</p>
<p>So we’ll start with the Final Four where I have #2 Ohio State from the South Region facing #6 San Diego State from the Midwest Region and #3 Kansas from the West Region facing #10 Maryland from the East Region.</p>
</div>
<div id="final-four" class="section level3">
<h3>Final Four</h3>
<pre class="r"><code>finalfour &lt;- tibble(
  Team=&quot;Ohio State&quot;,
  Opponent=&quot;San Diego State&quot;,
  Date = as.Date(&quot;2021-04-03&quot;)
)  %&gt;% add_row(
  Team=&quot;Kansas&quot;,
  Opponent=&quot;Maryland&quot;,
  Date = as.Date(&quot;2021-04-03&quot;)
)</code></pre>
<pre class="r"><code>finalfour &lt;- selectedrollinggames %&gt;% group_by(Team) %&gt;% filter(Date == max(Date)) %&gt;% select(-Date, -Opponent, -Outcome) %&gt;% right_join(finalfour)</code></pre>
<pre><code>## Joining, by = &quot;Team&quot;</code></pre>
<pre class="r"><code>finalfour &lt;- opponentrollinggames %&gt;% group_by(Opponent) %&gt;% filter(Date == max(Date)) %&gt;% ungroup()  %&gt;% select(-Season, -Date, -Outcome) %&gt;% right_join(finalfour, by=c(&quot;Opponent&quot;)) %&gt;% select(Team, everything())</code></pre>
<pre class="r"><code>finalfour &lt;- superdata_fit %&gt;% predict(new_data = finalfour) %&gt;% bind_cols(finalfour) </code></pre>
<pre class="r"><code>superdata_fit %&gt;% predict(new_data = finalfour, type=&quot;prob&quot;) %&gt;% bind_cols(finalfour)</code></pre>
<pre><code>## # A tibble: 2 x 15
##   .pred_L .pred_W .pred_class Team  Opponent Opponent_Rollin… Opponent_Rollin…
##     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;       &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;            &lt;dbl&gt;
## 1   0.276   0.724 W           Kans… Maryland             70.6             1.13
## 2   0.570   0.430 L           Ohio… San Die…             66.6             1.29
## # … with 8 more variables: Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;,
## #   Season &lt;chr&gt;, Rolling_Mean_Possessions &lt;dbl&gt;, Rolling_Mean_PPP &lt;dbl&gt;,
## #   Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;, Date &lt;date&gt;</code></pre>
<p>After all that it’s the Western Regional Champion #3 Kansas Jayhawks vs the Southern Regional Champion #6 San Diego State Aztecs.</p>
<p>I wonder, when it’s all said and done, if this ship will need to be hauled from landlocked Kansas to set sail, or will San Diego State be able to just plop it onto the Pacific Ocean?</p>
</div>
<div id="championship" class="section level3">
<h3>Championship</h3>
<pre class="r"><code>ship &lt;- tibble(
  Team=&quot;Kansas&quot;,
  Opponent=&quot;San Diego State&quot;,
  Date = as.Date(&quot;2021-04-05&quot;)
)</code></pre>
<pre class="r"><code>ship &lt;- selectedrollinggames %&gt;% group_by(Team) %&gt;% filter(Date == max(Date)) %&gt;% select(-Date, -Opponent, -Outcome) %&gt;% right_join(ship)</code></pre>
<pre><code>## Joining, by = &quot;Team&quot;</code></pre>
<pre class="r"><code>ship &lt;- opponentrollinggames %&gt;% group_by(Opponent) %&gt;% filter(Date == max(Date)) %&gt;% ungroup()  %&gt;% select(-Season, -Date, -Outcome) %&gt;% right_join(ship, by=c(&quot;Opponent&quot;)) %&gt;% select(Team, everything())</code></pre>
<pre class="r"><code>ship &lt;- superdata_fit %&gt;% predict(new_data = ship) %&gt;% bind_cols(ship) </code></pre>
<pre class="r"><code>superdata_fit %&gt;% predict(new_data = ship, type=&quot;prob&quot;) %&gt;% bind_cols(ship)</code></pre>
<pre><code>## # A tibble: 1 x 15
##   .pred_L .pred_W .pred_class Team  Opponent Opponent_Rollin… Opponent_Rollin…
##     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;       &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;            &lt;dbl&gt;
## 1   0.306   0.694 W           Kans… San Die…             66.6             1.29
## # … with 8 more variables: Opponent_Rolling_Mean_EFG &lt;dbl&gt;, OpponentSRS &lt;dbl&gt;,
## #   Season &lt;chr&gt;, Rolling_Mean_Possessions &lt;dbl&gt;, Rolling_Mean_PPP &lt;dbl&gt;,
## #   Rolling_Mean_EFG &lt;dbl&gt;, TeamSRS &lt;dbl&gt;, Date &lt;date&gt;</code></pre>
<p>It turns out it will be the Kansas Jayhawks getting to haul their ’ship to the nearest body of water to set sail, as they are your 2021 NCAA Men’s Basketball Champions.</p>
<p>To clear up any possible confusion of how the random forest works, if you look at the code, .pred_W is the predicted chance that the Team will win. So an average of around 69% of the trees in the random forest had Kansas beating San Diego State.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
  </body>
</html>

